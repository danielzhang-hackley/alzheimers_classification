{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import f_oneway, mannwhitneyu, shapiro\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = pd.read_csv(r'../../data/clean/gene_expression.csv')\n",
    "cnv = pd.read_csv(r'../../data/clean/cnv.csv')\n",
    "cnv_full = pd.read_csv(r'../../data/cnv.csv')\n",
    "met = pd.read_csv(r'../../data/clean/metabolomics.csv')\n",
    "labels = pd.read_csv(r'../../data/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "cnv.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "cnv_full.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "met.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "labels.drop(columns=\"Unnamed: 0\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split labels into classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emci = labels[labels[\"DX_bl\"] == \"EMCI\"].reset_index(drop=True)\n",
    "cn = labels[labels[\"DX_bl\"] == \"CN\"].reset_index(drop=True)\n",
    "lmci = labels[labels[\"DX_bl\"] == \"LMCI\"].reset_index().drop(columns='index')\n",
    "# ad = labels[labels[\"DX_bl\"] == \"AD\"].reset_index().drop(columns='index')\n",
    "\n",
    "targets = pd.concat([cn, emci, lmci]).reset_index(drop=True)\n",
    "encoding = {\"CN\": 0, \"EMCI\": 1, \"LMCI\": 1}\n",
    "targets.loc[:, \"DX_bl\"] = targets[\"DX_bl\"].map(encoding)\n",
    "targets = targets.astype({\"DX_bl\": \"int16\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = exp.merge(targets[[\"PTID\"]], how='inner', on=\"PTID\")\n",
    "cnv = cnv.merge(targets[[\"PTID\"]], how='inner', on=\"PTID\")\n",
    "cnv_full = cnv_full.merge(targets[[\"PTID\"]], how='inner', on=\"PTID\")\n",
    "met = met.merge(targets[[\"PTID\"]], how='inner', on=\"PTID\")\n",
    "\n",
    "exp.sort_values(by=\"PTID\", ignore_index=True, inplace=True)\n",
    "cnv.sort_values(by=\"PTID\", ignore_index=True, inplace=True)\n",
    "cnv_full.sort_values(by=\"PTID\", ignore_index=True, inplace=True)\n",
    "met.sort_values(by=\"PTID\", ignore_index=True, inplace=True)\n",
    "targets.sort_values(by=\"PTID\", ignore_index=True, inplace=True)\n",
    "\n",
    "exp_np = exp.select_dtypes(include=np.number).to_numpy()\n",
    "cnv_full_np = cnv_full.select_dtypes(include=np.number).to_numpy()\n",
    "met_np = met.select_dtypes(include=np.number).to_numpy()\n",
    "targets_np = targets[['DX_bl']].to_numpy().ravel()\n",
    "\n",
    "cnv_full_np_log = np.log2(cnv_full_np + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.293653371820192"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(exp_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "606",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# VARIANCE\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m omic_meta \u001b[38;5;129;01min\u001b[39;00m (exp_meta, cnv_meta, met_meta):\n\u001b[0;32m---> 11\u001b[0m     omic_meta[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43momic_meta\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     12\u001b[0m     omic_meta[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m omic_meta[test_idx]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m omic_meta \u001b[38;5;129;01min\u001b[39;00m (exp_meta, cnv_meta, met_meta):\n",
      "\u001b[0;31mKeyError\u001b[0m: 606"
     ]
    }
   ],
   "source": [
    "exp_meta = {'data': exp_np,          'pval_thresh': 0.2,  'var_thresh': 0.01}\n",
    "cnv_meta = {'data': cnv_full_np_log, 'pval_thresh': 0.01, 'var_thresh': 0.01}\n",
    "met_meta = {'data': met_np,          'pval_thresh': 0.2,  'var_thresh': 0.01}\n",
    "\n",
    "train_idx = np.arange(targets_np.shape[0])\n",
    "test_idx = []\n",
    "\n",
    "\n",
    "# VARIANCE\n",
    "for omic_meta in (exp_meta, cnv_meta, met_meta):\n",
    "    omic_meta['train'] = omic_meta[train_idx]\n",
    "    omic_meta['test'] = omic_meta[test_idx]\n",
    "\n",
    "for omic_meta in (exp_meta, cnv_meta, met_meta):\n",
    "    var_sel = VarianceThreshold(omic_meta['var_thresh'])\n",
    "    omic_meta['data'] = var_sel.fit_transform(omic_meta['data'])\n",
    "    omic_meta['var_sel'] = var_sel\n",
    "\n",
    "\n",
    "# SIGNIFICANCE\n",
    "for omic_meta in (exp_meta, cnv_meta, met_meta):\n",
    "    pvals = np.ones((omic_meta['train'].shape[1]))\n",
    "    for j in range(omic_meta['train'].shape[1]):\n",
    "        pos = omic_meta['train'][targets_np[train_idx] == 1, j].ravel()\n",
    "        neg = omic_meta['train'][targets_np[train_idx] == 0, j].ravel()\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            _, p = f_oneway(pos, neg)\n",
    "\n",
    "        pvals[j] = p\n",
    "\n",
    "    pvals = np.nan_to_num(pvals, nan=1.0)\n",
    "\n",
    "    omic_meta['sig_idx'] = np.nonzero(pvals < omic_meta['pval_thresh'])[0]\n",
    "    omic_meta['train'] = omic_meta['train'][omic_meta['sig_idx']]\n",
    "    omic_meta['test'] = omic_meta['test'][omic_meta['sig_idx']]\n",
    "\n",
    "\n",
    "exp_meta['idx_bnds': (0, exp_meta['train'].shape[1] - 1)]\n",
    "cnv_meta['idx_bnds': (exp_meta['idx_bnds'][1] + 1, exp_meta['idx_bnds'][1] + cnv_meta['train'].shape[1])]\n",
    "met_meta['idx_bnds': (cnv_meta['idx_bnds'][1] + 1, cnv_meta['idx_bnds'][1] + met_meta['train'].shape[1])]\n",
    "\n",
    "X_train = np.concatenate(exp_meta['train'], cnv_meta['train'], met_meta['train'])\n",
    "X_test = np.concatenate(exp_meta['test'], cnv_meta['test'], met_meta['test'])\n",
    "\n",
    "\n",
    "# CORRELATION\n",
    "# remove Highly Correlated Features from the dataset\n",
    "corr_matrix = np.abs(np.corrcoef(X_train, rowvar=False))\n",
    "upper = np.where(\n",
    "    np.logical_and(\n",
    "        corr_matrix, np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "    ), corr_matrix, 0\n",
    ")\n",
    "\n",
    "# drop features with high similarity\n",
    "cutoff = 0.8\n",
    "drop_mask = [any(upper[:, column] > cutoff) for column in range(upper.shape[1])]\n",
    "\n",
    "\n",
    "# RANDOM FOREST\n",
    "forest = RandomForestClassifier(random_state=0, class_weight='balanced', n_jobs=-1)\n",
    "forest.fit(X_train, targets_np[train_idx])\n",
    "for omic_meta in (exp_meta, cnv_meta, met_meta):\n",
    "    omic_meta['rf_idx'] = np.nonzero(forest.feature_importances_ > 0.0)[0]\n",
    "    omic_meta['train'] = omic_meta['train'][omic_meta['rf_idx']]\n",
    "    omic_meta['test'] = omic_meta['test'][omic_meta['rf_idx']]\n",
    "\n",
    "    print(omic_meta['rf_idx'])\n",
    "    print(len(omic_meta['rf_idx']))\n",
    "print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(606,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_np.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b690e49d2a1902140dda43f50cb0056ab0e985657f39fba6f94422d042b610e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
