{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = pd.read_csv(r'../../data/clean/gene_expression.csv')\n",
    "cnv = pd.read_csv(r'../../data/clean/cnv.csv')\n",
    "met = pd.read_csv(r'../../data/clean/metabolomics.csv')\n",
    "labels = pd.read_csv(r'../../data/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "cnv.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "met.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "labels.drop(columns=\"Unnamed: 0\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split labels into classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "emci = labels[labels[\"DX_bl\"] == \"EMCI\"].reset_index(drop=True)\n",
    "cn = labels[labels[\"DX_bl\"] == \"CN\"].reset_index(drop=True)\n",
    "lmci = labels[labels[\"DX_bl\"] == \"LMCI\"].reset_index().drop(columns='index')\n",
    "# ad = labels[labels[\"DX_bl\"] == \"AD\"].reset_index().drop(columns='index')\n",
    "\n",
    "targets = pd.concat([cn, emci, lmci]).reset_index(drop=True)\n",
    "encoding = {\"CN\": 0, \"EMCI\": 1, \"LMCI\": 2}\n",
    "targets.loc[:, \"DX_bl\"] = targets[\"DX_bl\"].map(encoding).astype(\"int16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "601    2\n",
       "602    2\n",
       "603    2\n",
       "604    2\n",
       "605    2\n",
       "Name: DX_bl, Length: 606, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[\"DX_bl\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get fold 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'unknown' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m kf \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39mn_folds, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m AUC, ACC \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_folds), np\u001b[38;5;241m.\u001b[39mzeros(n_folds)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (train, test) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(kf\u001b[38;5;241m.\u001b[39msplit(targets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPTID\u001b[39m\u001b[38;5;124m\"\u001b[39m], targets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDX_bl\u001b[39m\u001b[38;5;124m\"\u001b[39m])):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# scale and merge data\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     ptids_test \u001b[38;5;241m=\u001b[39m targets[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPTID\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mloc[test, :]\n\u001b[1;32m      8\u001b[0m     ptids_train \u001b[38;5;241m=\u001b[39m targets[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPTID\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mloc[train, :]\n",
      "File \u001b[0;32m~/Projects/alzheimers_sinai/phase_2/venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py:352\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits \u001b[39m>\u001b[39m n_samples:\n\u001b[1;32m    345\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    346\u001b[0m         (\n\u001b[1;32m    347\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCannot have number of splits n_splits=\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m greater\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    348\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m than the number of samples: n_samples=\u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    349\u001b[0m         )\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits, n_samples)\n\u001b[1;32m    350\u001b[0m     )\n\u001b[0;32m--> 352\u001b[0m \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39msplit(X, y, groups):\n\u001b[1;32m    353\u001b[0m     \u001b[39myield\u001b[39;00m train, test\n",
      "File \u001b[0;32m~/Projects/alzheimers_sinai/phase_2/venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py:85\u001b[0m, in \u001b[0;36mBaseCrossValidator.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     83\u001b[0m X, y, groups \u001b[39m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m     84\u001b[0m indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(_num_samples(X))\n\u001b[0;32m---> 85\u001b[0m \u001b[39mfor\u001b[39;00m test_index \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_test_masks(X, y, groups):\n\u001b[1;32m     86\u001b[0m     train_index \u001b[39m=\u001b[39m indices[np\u001b[39m.\u001b[39mlogical_not(test_index)]\n\u001b[1;32m     87\u001b[0m     test_index \u001b[39m=\u001b[39m indices[test_index]\n",
      "File \u001b[0;32m~/Projects/alzheimers_sinai/phase_2/venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py:733\u001b[0m, in \u001b[0;36mStratifiedKFold._iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_iter_test_masks\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, groups\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 733\u001b[0m     test_folds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_test_folds(X, y)\n\u001b[1;32m    734\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits):\n\u001b[1;32m    735\u001b[0m         \u001b[39myield\u001b[39;00m test_folds \u001b[39m==\u001b[39m i\n",
      "File \u001b[0;32m~/Projects/alzheimers_sinai/phase_2/venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676\u001b[0m, in \u001b[0;36mStratifiedKFold._make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    674\u001b[0m allowed_target_types \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    675\u001b[0m \u001b[39mif\u001b[39;00m type_of_target_y \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m allowed_target_types:\n\u001b[0;32m--> 676\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    677\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSupported target types are: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. Got \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    678\u001b[0m             allowed_target_types, type_of_target_y\n\u001b[1;32m    679\u001b[0m         )\n\u001b[1;32m    680\u001b[0m     )\n\u001b[1;32m    682\u001b[0m y \u001b[39m=\u001b[39m column_or_1d(y)\n\u001b[1;32m    684\u001b[0m _, y_idx, y_inv \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y, return_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_inverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'unknown' instead."
     ]
    }
   ],
   "source": [
    "n_folds = 5\n",
    "kf = StratifiedKFold(n_splits=n_folds, random_state=42, shuffle=True)\n",
    "AUC, ACC = np.zeros(n_folds), np.zeros(n_folds)\n",
    "\n",
    "for i, (train, test) in enumerate(kf.split(targets[\"PTID\"], targets[\"DX_bl\"])):\n",
    "    # scale and merge data\n",
    "    ptids_test = targets[[\"PTID\"]].loc[test, :]\n",
    "    ptids_train = targets[[\"PTID\"]].loc[train, :]\n",
    "\n",
    "    exp_sc = StandardScaler()\n",
    "    cnv_sc = StandardScaler()\n",
    "    met_sc = StandardScaler()\n",
    "\n",
    "    exp_train = exp.merge(ptids_train, how='inner', on=\"PTID\")\n",
    "    cnv_train = cnv.merge(ptids_train, how='inner', on=\"PTID\")\n",
    "    met_train = met.merge(ptids_train, how='inner', on=\"PTID\")\n",
    "\n",
    "    exp_train.loc[:, exp_train.columns != \"PTID\"] = exp_sc.fit_transform(exp_train.loc[:, exp_train.columns != \"PTID\"])\n",
    "    cnv_train.loc[:, cnv_train.columns != \"PTID\"] = cnv_sc.fit_transform(cnv_train.loc[:, cnv_train.columns != \"PTID\"])\n",
    "    met_train.loc[:, met_train.columns != \"PTID\"] = met_sc.fit_transform(met_train.loc[:, met_train.columns != \"PTID\"])\n",
    "\n",
    "    exp_test = exp.merge(ptids_test, how='inner', on=\"PTID\")\n",
    "    cnv_test = cnv.merge(ptids_test, how='inner', on=\"PTID\")\n",
    "    met_test = met.merge(ptids_test, how='inner', on=\"PTID\")\n",
    "\n",
    "    exp_test.loc[:, exp_test.columns != \"PTID\"] = exp_sc.transform(exp_test.loc[:, exp_test.columns != \"PTID\"])\n",
    "    cnv_test.loc[:, cnv_test.columns != \"PTID\"] = cnv_sc.transform(cnv_test.loc[:, cnv_test.columns != \"PTID\"])\n",
    "    met_test.loc[:, met_test.columns != \"PTID\"] = met_sc.transform(met_test.loc[:, met_test.columns != \"PTID\"])\n",
    "\n",
    "    master_train = exp_train.merge(targets, how='inner', on=\"PTID\")\\\n",
    "                            .merge(cnv_train, how='inner', on=\"PTID\")\\\n",
    "                            .merge(met_train, how='inner', on=\"PTID\")\n",
    "    master_test  = exp_test .merge(targets, how='inner', on=\"PTID\")\\\n",
    "                            .merge(cnv_test, how='inner', on=\"PTID\")\\\n",
    "                            .merge(met_test, how='inner', on=\"PTID\")\n",
    "\n",
    "    X_train = master_train.drop(columns=[\"DX_bl\", \"PTID\"]).to_numpy()\n",
    "    X_test = master_test.drop(columns=[\"DX_bl\", \"PTID\"]).to_numpy()\n",
    "    y_train = master_train[[\"DX_bl\"]].to_numpy().ravel().astype('int')\n",
    "    y_test = master_test[[\"DX_bl\"]].to_numpy().ravel().astype('int')\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started scaling and merging data for fold 1... "
     ]
    }
   ],
   "source": [
    "for i, (train, test) in enumerate(kf.split(targets[\"PTID\"], targets[\"DX_bl\"])):\n",
    "    # THE INDICES IN train AND test ARE TAKEN FROM targets, NOT ptid_list\n",
    "\n",
    "    print(f\"Started scaling and merging data for fold {i+1}... \", end='')\n",
    "\n",
    "    # scale and merge data\n",
    "    ptids_test = targets[[\"PTID\"]].loc[test, :]\n",
    "    ptids_train = targets[[\"PTID\"]].loc[train, :]\n",
    "\n",
    "    exp_sc = StandardScaler()\n",
    "    cnv_sc = StandardScaler()\n",
    "    met_sc = StandardScaler()\n",
    "\n",
    "    exp_train = exp.merge(ptids_train, how='inner', on=\"PTID\")\n",
    "    # cnv_train = cnv.merge(ptids_train, how='inner', on=\"PTID\")\n",
    "    # met_train = met.merge(ptids_train, how='inner', on=\"PTID\")\n",
    "\n",
    "    exp_train.loc[:, exp_train.columns != \"PTID\"] = exp_sc.fit_transform(exp_train.loc[:, exp_train.columns != \"PTID\"])\n",
    "    # cnv_train.loc[:, cnv_train.columns != \"PTID\"] = cnv_sc.fit_transform(cnv_train.loc[:, cnv_train.columns != \"PTID\"])\n",
    "    # met_train.loc[:, met_train.columns != \"PTID\"] = met_sc.fit_transform(met_train.loc[:, met_train.columns != \"PTID\"])\n",
    "\n",
    "    exp_test = exp.merge(ptids_test, how='inner', on=\"PTID\")\n",
    "    # cnv_test = cnv.merge(ptids_test, how='inner', on=\"PTID\")\n",
    "    # met_test = met.merge(ptids_test, how='inner', on=\"PTID\")\n",
    "\n",
    "    exp_test.loc[:, exp_test.columns != \"PTID\"] = exp_sc.transform(exp_test.loc[:, exp_test.columns != \"PTID\"])\n",
    "    # cnv_test.loc[:, cnv_test.columns != \"PTID\"] = cnv_sc.transform(cnv_test.loc[:, cnv_test.columns != \"PTID\"])\n",
    "    # met_test.loc[:, met_test.columns != \"PTID\"] = met_sc.transform(met_test.loc[:, met_test.columns != \"PTID\"])\n",
    "\n",
    "    master_train = exp_train.merge(targets, how='inner', on=\"PTID\")  # \\\n",
    "                            # .merge(cnv_train, how='inner', on=\"PTID\")\\\n",
    "                            # .merge(met_train, how='inner', on=\"PTID\")\n",
    "    master_test  = exp_test .merge(targets, how='inner', on=\"PTID\")  # \\\n",
    "                            # .merge(cnv_test, how='inner', on=\"PTID\")\\\n",
    "                            # .merge(met_test, how='inner', on=\"PTID\")\n",
    "\n",
    "    X_train = master_train.drop(columns=[\"DX_bl\", \"PTID\"]).to_numpy()\n",
    "    X_test = master_test.drop(columns=[\"DX_bl\", \"PTID\"]).to_numpy()\n",
    "    y_train = master_train[[\"DX_bl\"]].to_numpy().ravel().astype('int')\n",
    "    y_test = master_test[[\"DX_bl\"]].to_numpy().ravel().astype('int')\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(r'../../data/testing/fold_1.npz', X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started scaling and merging data for fold 1... Done\n",
      "Started tuning RF for fold 1... Done\n",
      "Elapsed time to tune RF: 1771.105 seconds\n",
      "Best parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 7, 'max_features': 0.5000000000000001, 'max_leaf_nodes': None, 'max_samples': 0.6000000000000001, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 180, 'n_jobs': None, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      "Test accuracy: 0.506024\n",
      "Test      AUC: 0.518648\n",
      "\n",
      "Started scaling and merging data for fold 2... Done\n",
      "Started tuning RF for fold 2... Done\n",
      "Elapsed time to tune RF: 1843.636 seconds\n",
      "Best parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 0.2, 'max_leaf_nodes': None, 'max_samples': 0.6000000000000001, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 130, 'n_jobs': None, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      "Test accuracy: 0.542169\n",
      "Test      AUC: 0.491841\n",
      "\n",
      "Started scaling and merging data for fold 3... Done\n",
      "Started tuning RF for fold 3... Done\n",
      "Elapsed time to tune RF: 1622.931 seconds\n",
      "Best parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 0.2, 'max_leaf_nodes': None, 'max_samples': 0.5000000000000001, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 150, 'n_jobs': None, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      "Test accuracy: 0.506024\n",
      "Test      AUC: 0.442105\n",
      "\n",
      "Started scaling and merging data for fold 4... Done\n",
      "Started tuning RF for fold 4... Done\n",
      "Elapsed time to tune RF: 2317.380 seconds\n",
      "Best parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 9, 'max_features': 0.4000000000000001, 'max_leaf_nodes': None, 'max_samples': 0.9000000000000001, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      "Test accuracy: 0.451220\n",
      "Test      AUC: 0.465909\n",
      "\n",
      "Started scaling and merging data for fold 5... Done\n",
      "Started tuning RF for fold 5... Done\n",
      "Elapsed time to tune RF: 2304.753 seconds\n",
      "Best parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 0.6000000000000001, 'max_leaf_nodes': None, 'max_samples': 0.4000000000000001, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 180, 'n_jobs': None, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      "Test accuracy: 0.524390\n",
      "Test      AUC: 0.534988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (train, test) in enumerate(kf.split(targets[\"PTID\"], targets[\"DX_bl\"])):\n",
    "    # THE INDICES IN train AND test ARE TAKEN FROM targets, NOT ptid_list\n",
    "\n",
    "    print(f\"Started scaling and merging data for fold {i+1}... \", end='')\n",
    "\n",
    "    # scale and merge data\n",
    "    ptids_test = targets[[\"PTID\"]].loc[test, :]\n",
    "    ptids_train = targets[[\"PTID\"]].loc[train, :]\n",
    "\n",
    "    exp_sc = StandardScaler()\n",
    "    cnv_sc = StandardScaler()\n",
    "    met_sc = StandardScaler()\n",
    "\n",
    "    exp_train = exp.merge(ptids_train, how='inner', on=\"PTID\")\n",
    "    # cnv_train = cnv.merge(ptids_train, how='inner', on=\"PTID\")\n",
    "    # met_train = met.merge(ptids_train, how='inner', on=\"PTID\")\n",
    "\n",
    "    exp_train.loc[:, exp_train.columns != \"PTID\"] = exp_sc.fit_transform(exp_train.loc[:, exp_train.columns != \"PTID\"])\n",
    "    # cnv_train.loc[:, cnv_train.columns != \"PTID\"] = cnv_sc.fit_transform(cnv_train.loc[:, cnv_train.columns != \"PTID\"])\n",
    "    # met_train.loc[:, met_train.columns != \"PTID\"] = met_sc.fit_transform(met_train.loc[:, met_train.columns != \"PTID\"])\n",
    "\n",
    "    exp_test = exp.merge(ptids_test, how='inner', on=\"PTID\")\n",
    "    # cnv_test = cnv.merge(ptids_test, how='inner', on=\"PTID\")\n",
    "    # met_test = met.merge(ptids_test, how='inner', on=\"PTID\")\n",
    "\n",
    "    exp_test.loc[:, exp_test.columns != \"PTID\"] = exp_sc.transform(exp_test.loc[:, exp_test.columns != \"PTID\"])\n",
    "    # cnv_test.loc[:, cnv_test.columns != \"PTID\"] = cnv_sc.transform(cnv_test.loc[:, cnv_test.columns != \"PTID\"])\n",
    "    # met_test.loc[:, met_test.columns != \"PTID\"] = met_sc.transform(met_test.loc[:, met_test.columns != \"PTID\"])\n",
    "\n",
    "    master_train = exp_train.merge(targets, how='inner', on=\"PTID\")  # \\\n",
    "                            # .merge(cnv_train, how='inner', on=\"PTID\")\\\n",
    "                            # .merge(met_train, how='inner', on=\"PTID\")\n",
    "    master_test  = exp_test .merge(targets, how='inner', on=\"PTID\")  # \\\n",
    "                            # .merge(cnv_test, how='inner', on=\"PTID\")\\\n",
    "                            # .merge(met_test, how='inner', on=\"PTID\")\n",
    "\n",
    "    X_train = master_train.drop(columns=[\"DX_bl\", \"PTID\"]).to_numpy()\n",
    "    X_test = master_test.drop(columns=[\"DX_bl\", \"PTID\"]).to_numpy()\n",
    "    y_train = master_train[[\"DX_bl\"]].to_numpy().ravel().astype('int')\n",
    "    y_test = master_test[[\"DX_bl\"]].to_numpy().ravel().astype('int')\n",
    "\n",
    "    print(\"Done\")\n",
    "\n",
    "    # scaling and merging complete\n",
    "\n",
    "    # calculate p-values for each feature\n",
    "    p_vals = np.ones((X_train.shape[1]))\n",
    "    # select relevant features\n",
    "    for j in range(X_train.shape[1]):\n",
    "        pos = X_train[y_train == 1, j]\n",
    "        neg = X_train[y_train == 0, j]\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            _, p = f_oneway(pos, neg)\n",
    "        p_vals[j] = p\n",
    "    p_vals = np.nan_to_num(p_vals, nan=1.0)\n",
    "    stat_sig_idx = np.where(p_vals < 0.05)[0]\n",
    "\n",
    "\n",
    "    # Feature importance based on feature permutation\n",
    "    forest = RandomForestClassifier(random_state=0, class_weight='balanced')\n",
    "    forest.fit(X_train, y_train)\n",
    "    forest_imp_idx = np.where(forest.feature_importances_ > 0.0)[0]\n",
    "\n",
    "\n",
    "    # select overlap genes (p<0.1 and importance by RF)\n",
    "    overlap = list(set(stat_sig_idx) & set(forest_imp_idx))\n",
    "    # print(len(overlap))\n",
    "    X_train = X_train[:, overlap]\n",
    "    X_test = X_test[:, overlap]\n",
    "\n",
    "\n",
    "    # tuning RF prediction parameters by exhaust grid search to optimize a prediction RF model\n",
    "    start_time = time.time()\n",
    "    print(f\"Started tuning RF for fold {i+1}... \", end='')\n",
    "    param_grid = {'n_estimators': np.arange(50, 200, 10),\n",
    "                'max_features': np.arange(0.2, 1, 0.1),\n",
    "                'max_depth': np.arange(1, 10, 1),\n",
    "                'max_samples': np.arange(0.2, 1, 0.1)}\n",
    "    model_grid = GridSearchCV(RandomForestClassifier(criterion='gini', random_state=0),\n",
    "                                        param_grid, n_jobs=-1).fit(X_train, y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(\"Done\")\n",
    "\n",
    "    print(f\"Elapsed time to tune RF: {elapsed_time:.3f} seconds\")\n",
    "    print(f\"Best parameters: {model.get_params()}\")\n",
    "\n",
    "    # predict using the model built\n",
    "    test_prob = model.predict_proba(X_test)\n",
    "    test_predict = model.predict(X_test)\n",
    "    AUC[i] = roc_auc_score(y_test, test_prob[:, 1])\n",
    "    ACC[i] = accuracy_score(y_test, test_predict)\n",
    "    print(\"Test accuracy: %f\" % ACC[i])\n",
    "    print(\"Test      AUC: %f\" % AUC[i])\n",
    "\n",
    "    # prepare the result output\n",
    "    if i == 0:\n",
    "        test_out = pd.DataFrame(test_prob)\n",
    "        test_out['predict'] = test_predict\n",
    "        test_out['class_label'] = y_test\n",
    "    else:\n",
    "        temp = pd.DataFrame(test_prob)\n",
    "        temp['predict'] = test_predict\n",
    "        temp['class_label'] = y_test\n",
    "        pd.concat([test_out, temp], axis=0)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out.to_csv(r'../../results/multiomics_emci-cn_rf_sigdiff-and-rf_pval0-1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b26c068b141905f0ff66e080ffe7b968e548408d059de0bd8590b52b4a0c2b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
